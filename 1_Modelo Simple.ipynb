{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os # Leer imagenes\n",
    "import torch # Armar modelos\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A # Augmentaciones\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder # Convertir los nombres de las clases en nums\n",
    "from tqdm import tqdm # Barra de proceso \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report # Levantar metricas\n",
    "import io # Python basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99449de6-85e8-41e9-b4ea-7e50866d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow # Training Tracking and Comparision\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3eea338-d373-4d32-8815-54ba0a156e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/santi/OneDrive/Escritorio/skin_dataset_clasification-AGOSTI/mlruns/618597791685242834', creation_time=1749738080759, experiment_id='618597791685242834', last_update_time=1749738080759, lifecycle_stage='active', name='MLP_Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MLP_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21eeefb-bc83-4931-acbc-65ca26d10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573d2f49-abfd-444a-a947-712c1737eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para loguear una figura matplotlib en TensorBoard\n",
    "def plot_to_tensorboard(fig, writer, tag, step):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "    writer.add_image(tag, image, global_step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4901b00e-6c31-4af2-ab6d-1cc383687d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para matriz de confusión y clasificación\n",
    "def log_classification_report(model, loader, writer, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.label_encoder.classes_)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=train_dataset.label_encoder.classes_)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6564e0-f970-461a-8ab4-5d19e0d55040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear directorio de logs\n",
    "run_name = f\"init_uniform\"  # or any custom string\n",
    "log_dir = f\"runs/{run_name}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41919c3b-76d8-4eb0-810a-62ce743752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        class_names = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "        for cls in class_names:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, fname))\n",
    "                    self.labels.append(cls)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bc0d2e4-319e-4f95-a59b-565182681864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32743888-c68f-4a1a-a5e0-afe766b91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a707a13e-87cc-4c2b-89fd-b83ff1fd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e18375e-9fb1-4084-8338-302ca99f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a9d4d33-e68d-4ccb-8b0e-f18deabc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=64*64*3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.init_weights()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.kaiming_normal_(m.weight)\n",
    "                #nn.init.xavier_uniform_\n",
    "                #nn.init.kaiming_normal_\n",
    "                nn.init.uniform_\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da9b8088-283f-4549-8c86-2fec28283e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, val_loader, writer, step=epoch, prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08d5e76-139b-43b0-a5f0-a781b0a22463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 22/22 [00:13<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 1.7203, Accuracy: 38.51%\n",
      "  Val   Loss: 1.4556, Accuracy: 42.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 22/22 [00:06<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 1.3220, Accuracy: 50.72%\n",
      "  Val   Loss: 1.2834, Accuracy: 51.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 22/22 [00:06<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 1.2000, Accuracy: 54.60%\n",
      "  Val   Loss: 1.1573, Accuracy: 50.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 22/22 [00:08<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 1.1384, Accuracy: 55.17%\n",
      "  Val   Loss: 1.1327, Accuracy: 52.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 22/22 [00:08<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 1.0792, Accuracy: 58.19%\n",
      "  Val   Loss: 1.0970, Accuracy: 58.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 22/22 [00:09<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 0.9626, Accuracy: 61.78%\n",
      "  Val   Loss: 1.0500, Accuracy: 58.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 22/22 [00:06<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 0.9293, Accuracy: 65.52%\n",
      "  Val   Loss: 1.0558, Accuracy: 56.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 22/22 [00:06<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 0.9263, Accuracy: 65.66%\n",
      "  Val   Loss: 1.0589, Accuracy: 55.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 22/22 [00:08<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 0.8382, Accuracy: 69.11%\n",
      "  Val   Loss: 1.1369, Accuracy: 56.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 22/22 [00:09<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 0.8469, Accuracy: 68.25%\n",
      "  Val   Loss: 1.0493, Accuracy: 62.78%\n"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento\n",
    "n_epochs = 10\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log hiperparámetros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"MLPClassifier\",\n",
    "        \"input_size\": 64*64*3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "    })\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "    val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "\n",
    "    # Log en MLflow\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    }, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e7a8964-f0dc-439c-b18b-b084c1afe531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 22:53:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 22:53:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo\n",
    "torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "mlflow.log_artifact(\"mlp_model.pth\")\n",
    "mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "print(\"Modelo guardado como 'mlp_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6b1701-9f75-45e7-9992-5758d9af612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "         writer.add_histogram(name, param, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
